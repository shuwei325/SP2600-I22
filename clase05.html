<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Series de tiempo II - Tópicos avanzados</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof. Shu Wei Chou C." />
    <script src="clase05_files/header-attrs/header-attrs.js"></script>
    <link href="clase05_files/remark-css/robot-fonts.css" rel="stylesheet" />
    <link href="clase05_files/remark-css/robot.css" rel="stylesheet" />
    <link href="clase05_files/remark-css/tamu.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Series de tiempo II - Tópicos avanzados
## (PF-1360 y SP-2600)
### Prof. Shu Wei Chou C.
### Posgrado en Matemática - Posgrado en Estadística, UCR
### 03-05-2022

---







### Tema II

### Análisis multivariado de series temporales


---
### Contenido

1. Introducción
2. Modelos ARMA vectoriales
3. Causalidad de Granger
4. Raíz unitarias
5. Procesos cointegrados: definición y pruebas de hipótesis para cointegración y modelos de corrección del error.

---
### Introducción 

- En la práctica, es común enfrentar situaciones en donde se presentan varias series temporales.

- **Objetivos:**
1. Estudiar la relación dinámica de las variables de interés en el tiempo.
2. Mejorar las predicciones.

---
### Introducción 

**Ejemplo 1: El Niño y la población de peces**

- Se tiene la serie ambiental de índice de oscilación del sur (SOI, Southern Oscillation Index), y la serie de número de peces nuevos (Reclutamiento) de 453 meses de 1950 a 1987.
- SOI mide cambios en presión relacionada a la temperatura del superficie del mar en el oceano pacífico central, el cual se calienta cada 3-7 años por el efecto El Niño.


&lt;img src="clase05_files/figure-html/unnamed-chunk-2-1.png" width="40%" style="display: block; margin: auto;" /&gt;



---
### Introducción 

**Ejemplo 2: Imagen por resonancia magnética**

- Un estímulo fue aplicado a cinco personas en la mano por 32 segundos y luego paró el estímulo por otros 32 segundos, sucesivamente.
- Durante 256 segundos, cada 2 segundos se registró la intensidad del dependiente del nivel en la sangre (BOLD, blood oxygenation-level dependent signal intensity), la cual mide áreas de activación en el celebro `\((T=128)\)`.

&lt;img src="clase05_files/figure-html/unnamed-chunk-3-1.png" width="40%" style="display: block; margin: auto;" /&gt;


---
### Medidas de dependencia (caso bivariada)

- Recuerde que **la función de autocorrelación** es definida por

`$$\rho_X(t,s)=\frac{\gamma(t,s)}{\sqrt{\gamma(t,t)\gamma(s,s)}}$$`

- Se puede generalizar estas medidas a dos series `\(X_t\)` y `\(Y_t\)`. Defina:

- **la función de autocovariancia cruzada**:

`$$\gamma_{XY}(t,s)= Cov(X_t,Y_s) =E\left[ (X_t-\mu_{Xt})(Y_s-\mu_{Ys}) \right]$$`


- **la función de autocorrelación cruzada**:

`$$\rho_{XY}(t,s)= \frac{\gamma_{XY}(t,s)}{\sqrt{\gamma_{X}(t,t)\gamma_{Y}(s,s)}}$$`




---
### Estacionariedad conjunta(caso bivariada)

**Definición:**
Dos series temporales, `\(X_t\)` y `\(Y_t\)` se dicen que son **conjuntamente estacionarias** si cada serie es estacionaria, y la función de covariancia cruzada

`$$\gamma_{XY}(h)= Cov(X_{t+h},Y_t) =E\left[ (X_{t+h}-\mu_{X})(Y_t-\mu_{Y}) \right]$$`
es una función que solamente depende de `\(h\)`.

De esta forma, podemos definir la función de correlación cruzada de dos series temporales conjuntamente estacionarias por `$$\rho_{XY}(h)=\frac{\gamma_{XY}(h)}{\sqrt{\gamma_X(0),\gamma_Y(0)}}$$`

**Propiedades:**
- `\(-1 \leq \rho_{XY}(h) \leq 1\)`
- `\(\rho_{XY}(h) \neq \rho_{XY}(-h)\)` pues `\(Cov(X_2,Y_1)\)` y `\(Cov(X_1,Y_2)\)` no siempre son iguales.
- `\(\rho_{XY}(h) = \rho_{YX}(-h)\)`

---
### Estimación

- **la función de autocovariancia cruzada muestral** es definida por
`$$\hat{\gamma}_{XY}(h)=\frac{1}{T}\sum_{t=1}^{T-h} (X_{t+h}-\bar{X})(Y_{t}-\bar{Y}),$$`

Note que `\(\hat{\gamma}_{XY}(-h)=\hat{\gamma}_{YX}(h)\)` para `\(h=0,1,...,T-1\)`.


- **La función de autocorrelación cruzada muestral** es definida por
`$$\hat{\rho}_{XY}(h)=\frac{\hat{\gamma}_{XY}(h)}{\sqrt{\hat{\gamma}_X(0)\hat{\gamma}_Y(0)}}$$`
**Propiedad:** La distribución de `\(\hat{\rho}_{XY}(h)\)` para `\(T\)` grande es aproximadamente normal con media cero y 
`$$\sigma_{\hat{\rho}_{XY}}=\frac{1}{\sqrt{T}}.$$`



---
### Ejemplo 1: El Niño y la población de peces

- Se tiene la serie ambiental de índice de oscilación del sur (SOI, Southern Oscillation Index), y la serie de número de peces nuevos (Reclutamiento) de 453 meses de 1950 a 1987.
- SOI mide cambios en presión relacionada a la temperatura del superficie del mar en el oceano pacífico central, el cual se calienta cada 3-7 años por el efecto El Niño.


&lt;img src="clase05_files/figure-html/unnamed-chunk-4-1.png" width="40%" style="display: block; margin: auto;" /&gt;


---
### Ejemplo: El Niño y la población de peces

**Gráfico de dispersión de series rezagadas**

&lt;img src="clase05_files/figure-html/unnamed-chunk-5-1.png" width="60%" style="display: block; margin: auto;" /&gt;


---
### Ejemplo: El Niño y la población de peces:

&lt;img src="clase05_files/figure-html/unnamed-chunk-6-1.png" width="60%" style="display: block; margin: auto;" /&gt;


---
### Ejemplo: El Niño y la población de peces

**Gráfico de dispersión de REC contra SOI rezagadas**

&lt;img src="clase05_files/figure-html/unnamed-chunk-7-1.png" width="60%" style="display: block; margin: auto;" /&gt;



---
### Ejemplo: El Niño y la población de peces:


```r
par(mfrow=c(2,1))
ccf2(rec,soi, 36, main="función de correlación cruzada de Rec. contra SOI")
ccf2(soi,rec, 36, main="función de correlación cruzada de SOI contra Rec.")
```

&lt;img src="clase05_files/figure-html/unnamed-chunk-8-1.png" width="50%" style="display: block; margin: auto;" /&gt;

---
### Ejemplo: El Niño y la población de peces:


```r
(r1=ccf(rec,soi, 5, plot=FALSE))
```

```
## 
## Autocorrelations of series 'X', by lag
## 
## -0.4167 -0.3333 -0.2500 -0.1667 -0.0833  0.0000  0.0833  0.1667  0.2500  0.3333 
##  -0.259  -0.228  -0.154  -0.086  -0.013   0.025   0.011  -0.042  -0.146  -0.297 
##  0.4167 
##  -0.527
```

```r
(r2=ccf(soi,rec, 5, plot=FALSE))
```

```
## 
## Autocorrelations of series 'X', by lag
## 
## -0.4167 -0.3333 -0.2500 -0.1667 -0.0833  0.0000  0.0833  0.1667  0.2500  0.3333 
##  -0.527  -0.297  -0.146  -0.042   0.011   0.025  -0.013  -0.086  -0.154  -0.228 
##  0.4167 
##  -0.259
```

- Note que `\(\hat{\rho}_{XY}(h) = \hat{\rho}_{YX}(-h)\)`.


---
### Medidas de dependencia (caso k-variada)

La generalización a series temporales multivariadas con `\(k\)` componentes, `\(X_{t1},...X_{tk}, t=1,...,T\)`, es intuitivo:

- **la función de autocovariancia cruzada**:

`$$\gamma_{ij}(t,s)= Cov(X_{ti},X_{sj}) =E\left[ (X_{ti}-\mu_{it})(X_{sj}-\mu_{js}) \right]$$`
para `\(i,j=1,...,k.\)`

---
### Estacionariedad conjunta (caso k-variada)

- Sea `\(X_t=(X_{t1},...,X_{tk})'\)` un vector `\(k \times 1\)` de series temporales. Se dice que `\(X_t\)` es (débilmente) estacionario si el vector de medias es constante en el tiempo
`$$\mu=E(X_t)=\left(\begin{array}{c} \mu_1\\ \vdots \\ \mu_k \end{array}\right)$$`

- Y la matriz de autocovariancia depende únicamente del rezago `\(h\)`, i.e.
`$$\Gamma(h)= E[(X_{t+h}-\mu)(X_{t}-\mu)' ]$$`
donde los elementos de la matriz son funciones de covariancia cruzada, `\(\gamma_{ij}(h)= Cov(X_{t+h,i},X_{t,j}) =E\left[ (X_{t+h,i}-\mu_{i})(X_{tj}-\mu_{j}) \right]\)` para `\(i,j=1,...,k\)`. 

- Note que como `\(\gamma_{ij}(h)=\gamma_{ji}(-h)\)`, entonces

`$$\Gamma(-h)=\Gamma'(h)$$`

---
### Estacionariedad conjunta (caso k-variada)

-  la matriz de autocorrelaciones también depende únicamente del rezago `\(h\)`, i.e.
`$$\boldsymbol{\rho}(h)= D^{-1}\Gamma(h) D^{-1}=\left[ \rho_{h,ij} \right]$$`
donde `\(D=diag\left\lbrace \sigma_1,...,\sigma_k \right\rbrace\)` es la matriz diagonal de desviaciones estándares de los componentes de `\(X_t\)`.

- Al igual que `\(\Gamma(h)\)`, se tiene que `$$\boldsymbol{\rho}(-h)=\boldsymbol{\rho}'(h)$$`

---
### Estacionariedad estricta conjunta

- Sea `\(X_t=(X_{t1},...,X_{tk})'\)` un vector `\(k \times 1\)` de series temporales. Se dice que `\(X_t\)` es estrictamente estacionario si la distribución conjunta multivariada de una colección de m tiempos:
`$$\left\lbrace X_{t_1},...,X_{t_m} \right\rbrace$$`
es igual a 
`$$\left\lbrace X_{t_1+h},...,X_{t_m+h} \right\rbrace$$`
donde `\(m,j\)` y `\((t_1,...,t_m)\)` son enteros positivos arbitrarios.

- Una serie temporal estrictamente estacionaria es débilmente estacionaria, si sus primeros dos momentos existen.


---
### Ruido blanco


- Es una colección de variables aleatorias no correlacionadas, `\(a_t\)`, con media `\(0\)` y matriz de covariancias `\(\Sigma_a\)`.

- Denotado por `\(a_t \sim wn(0,\Sigma_a)\)`.

- Si una secuencia de variables es i.i.d., i.e. `\(a_t \sim iid(0,\Sigma_a)\)`, entonces `\(a_t \sim wn(0,\Sigma_a)\)`.

- Sin embargo, si un ruido blanco es Gaussiano, entonces `\(a_t \overset{iid}{\sim} N(0,\Sigma_a)\)`.


---

### Ruido blanco
.pull-left[

- Considere un ruido blanco Gaussiano:
`$$a_t \sim N\left(0, 
\begin{bmatrix}1.5 &amp; 0.8 \\
 0.8 &amp; 1
\end{bmatrix} \right).$$`

- Note que su función de autocovariancia es 
$$
\Gamma(h)=\left\lbrace 
`\begin{aligned}
\begin{bmatrix}1.5 &amp; 0.8 \\
 0.8 &amp; 1
\end{bmatrix}  &amp; &amp; h = 0 \\
0, &amp; &amp;  h \neq 0,
\end{aligned}`
\right.$$`
]
.pull-right[
- Simulación con `\(T=500\)`.
&lt;img src="clase05_files/figure-html/unnamed-chunk-10-1.png" width="90%" /&gt;
]


---

### Ruido blanco

&lt;img src="clase05_files/figure-html/unnamed-chunk-11-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---
### Linealidad

- En la práctica, la mayoría de las series temporales multivariadas no son lineales pero pueden ser aproximada por modelos lineales.

- Defina el modelo lineal (multivariado):

`$$X_t=\mu+\sum_{i=0}^\infty \psi_i a_{t-i}=\mu+ a_{t}+\sum_{i=1}^\infty \psi_i a_{t-i}$$`
donde `\(\mu\)` es un vector constante,
`\(\psi_0=I_k\)` es una matriz de identidad de `\(k\times k\)`, 
`\(\psi_i,~i&gt;0\)` matrices constantes, y
`\(\left\lbrace a_{t}\right\rbrace\)`, denominado como **innovación**, es una secuencia de i.i.d. vectores aleatorias con media 0 y matriz de covariancias `\(\Sigma_a\)`, una matriz definitva positiva.

- El modelo lineal también se puede escribir como:
  - `\(X_t=\mu+ a_{t} + \psi_1 a_{t-1}+ \psi_2 a_{t-2} + \dots\)`
  - `\(X_t=\mu+\psi(B) a_{t}\)`,   
  donde `\(\psi(B)=1+\psi_1 B+\psi_2 B^2+\dots\)` es el polinomio de medias móviles de orden infinito.


---
### Linealidad

- Un modelo lineal es estacionario si los componentes `\(\psi_i\)` es absolutamente sumable, i.e.

$$\sum_{i=1}^\infty ||\psi_i|| &lt; \infty $$
donde `\(||A||\)` denota la norma de la matriz `\(A\)`. Un ejemplo es la norma Frobenius `\(||A||=\sqrt{tr(AA')}\)`

- Como consecuencia, `\(\psi_i \rightarrow 0\)` si `\(i \rightarrow \infty\)`.

- Y tenemos que si `\(X_t\)` es estacionario, entonces
`$$E(X_t)=\mu,~~ \Gamma(h)=\sum_{i=0}^\infty \psi_{i+h} \Sigma_a \psi_i'$$`
- Similar al caso univariado, tanto AR, MA y ARMA forman casos particulares de un modelo lineal.

---
### Invertibilidad

- El interés es expresar una serie tepmoral `\(X_t\)` en término de sus valores pasados `\(X_{t-i}\)` para `\(i&gt;0\)`.

- Una serie temporal `\(X_t\)` es invertible si se puede expresar como:
`$$X_t=c+a_t+\sum_{j=0}^\infty \pi_j X_{t-j}$$`
donde `\(c\)` es un vector constante,
`\(\pi_j,~j&gt;0\)` matrices constantes `\(k\times k\)`, y
`\(\left\lbrace a_{t}\right\rbrace\)` es una secuencia de i.i.d. vectores aleatorias con media 0 y matriz de covariancias `\(\Sigma_a\)`.

- Un modelo invertible también se puede expresar como:

  - `\(X_t-\sum\limits_{j=0}^\infty \pi_j X_{t-j}=c+a_t\)`, o
  - `\(\pi(B)X_t =c+a_t\)`,   
  donde `\(\pi(B)=1-\sum\limits_{j=0}^\infty \pi_j B\)` es el polinomio autorregresivo de orden infinito.


---
### Estimación de matrices de covariancia cruzada y correlación cruzada

- **la matriz de covariancia cruzada muestral** es definida por
`$$\hat{\Gamma}(h)=\frac{1}{T}\sum_{t=1}^{T-h} (X_{t+h}-\bar{X})(X_{t}-\bar{X})',$$`
donde `\(\bar{X}=\frac{1}{T}\sum\limits_{t=1}^{T} X_{t}\)` es el vector de media muestral.


- **la matriz de correlación cruzada muestral (CCM)** es definida por

`$$\hat{\boldsymbol{\rho}}(h)= \hat{D}^{-1}\hat{\Gamma}(h) \hat{D}^{-1}$$`
donde `\(\hat{D}=diag\left\lbrace \hat{\gamma}_{0,11}^{1/2},...,\hat{\gamma}_{0,kk}^{1/2} \right\rbrace\)` y `\(\hat{\gamma}_{0,ii}\)` es el i-ésimo elemento de `\(\hat{\Gamma(0)}\)`.

- Se puede comprobar que `\(\hat{\Gamma}(-h)=\hat{\Gamma}(h)'\)` y `\(\hat{\boldsymbol{\rho}}(-h)=\hat{\boldsymbol{\rho}}(h)'\)`

---
### Estimación de matrices de covariancia cruzada y correlación cruzada

- Si `\(X_t\)` es ruido blanco, entonces
`$$Var(\hat{\rho}_{h,ij}) \approx \frac{1}{T},~~ h&gt;0$$`
`$$Var(\hat{\rho}_{0,ij}) \approx \frac{(1-\rho_{h,ij})^2}{T},~~ i \neq j$$`
`$$Cov(\hat{\rho}_{h,ij},\hat{\rho}_{-h,ij}) \approx \frac{\rho_{0,ij}^2}{T}$$`
`$$Cov(\hat{\rho}_{h,ij},\hat{\rho}_{l,uv}) \approx 0, h \neq l$$`

---
### Estimación de matrices de covariancia cruzada y correlación cruzada

- Si `\(X_t\)` es VMA(q), entonces
`$$Var(\hat{\rho}_{h,ij}) \approx \frac{1}{T} \left( 1+2\sum_{v=1}^{q} \rho_{v,ii}\rho_{v,jj} \right),~~ |h|&gt;q$$`

- En la práctica, cuando k es grande, es complicado estudiar `\(k^2\)` correlaciones cruzadas simultáneamente.

---
### Estimación de matrices de covariancia cruzada y correlación cruzada

- La matriz simplificada de CCM:

`$$s_{h,ij} = \left\lbrace \begin{eqnarray} + &amp; ~~&amp; \text{si}~~\hat{\rho}_{h,ij} \geq 2/\sqrt{T} \\ -&amp; ~~&amp;\text{si}~~ \hat{\rho}_{h,ij} \leq -2/\sqrt{T} \\ . &amp; ~~&amp; \text{si}~~ |\hat{\rho}_{h,ij}| &lt; 2/\sqrt{T}  \end{eqnarray}\right.$$`

- Nos indican cuáles son significativos a un 5% de significancia bajo el supuesto de un ruido blanco.

---
### Ruido blanco

.pull-left[

- Considere
`$$a_t \sim N\left(0, 
\begin{bmatrix}1.5 &amp; 0.8 \\
 0.8 &amp; 1
\end{bmatrix} \right).$$`

- Note que su función de autocovariancia es 
$$
\Gamma(h)=\left\lbrace 
`\begin{aligned}
\begin{bmatrix}1.5 &amp; 0.8 \\
 0.8 &amp; 1
\end{bmatrix}  &amp; &amp; h = 0 \\
0, &amp; &amp;  h \neq 0,
\end{aligned}`
\right.$$`
]
.pull-right[
- Simulación con `\(T=500\)`.
&lt;img src="clase05_files/figure-html/unnamed-chunk-12-1.png" width="90%" /&gt;
]

---

### Ruido blanco


```r
ccm(aa, lags= 4) 
```

```
## [1] "Covariance matrix:"
##       a1    a2
## a1 1.387 0.728
## a2 0.728 0.996
## CCM at lag:  0 
##      [,1] [,2]
## [1,] 1.00 0.62
## [2,] 0.62 1.00
## Simplified matrix: 
## CCM at lag:  1 
## . . 
## . . 
## CCM at lag:  2 
## . . 
## . . 
## CCM at lag:  3 
## . . 
## . . 
## CCM at lag:  4 
## . . 
## . .
```

&lt;img src="clase05_files/figure-html/unnamed-chunk-13-1.png" width="100%" /&gt;

```
## Hit Enter for p-value plot of individual ccm:
```

&lt;img src="clase05_files/figure-html/unnamed-chunk-13-2.png" width="100%" /&gt;

---
### Estimación de matrices de covariancia cruzada y correlación cruzada

- Otra posibilidad es usar correlograma y función de autocorrelación cruzada.


&lt;img src="clase05_files/figure-html/unnamed-chunk-14-1.png" width="50%" style="display: block; margin: auto;" /&gt;


---
### Prueba de hipótesis para la correlación serial con CCM

- Al igual que el caso univariado, se plantean las hipótesis:   

`\(H_0: \boldsymbol{\Gamma}_1=...=\boldsymbol{\Gamma}_m=0\)`  
`\(H_1: \boldsymbol{\Gamma}_i \neq 0\)`, para algún `\(1\leq i \leq m\)`

o bien,

`\(H_0: \boldsymbol{\rho}_1=...=\boldsymbol{\rho}_m=0\)`  
`\(H_1: \boldsymbol{\rho}_i \neq 0\)`, para algún `\(1\leq i \leq m\)`

---
### Prueba de hipótesis para la correlación serial con CCM


- **El estadístico de Portmanteau multivariado:** la versión multivariada de la prueba de Ljung-Box.
`$$Q_m=T^2 \sum_{l=1}^m \frac{1}{T-l} tr \left(\hat{\boldsymbol{\Gamma}}'_l\hat{\boldsymbol{\Gamma}}^{-1}_0\hat{\boldsymbol{\Gamma}}_l\hat{\boldsymbol{\Gamma}}^{-1}_0\right)$$`

donde `\(tr(A)\)` es la traza de la matriz A. 

- Bajo el supuesto de `\(H_0\)`,i.e. `\(\boldsymbol{\Gamma}_l=0,~ l&gt;0\)`, y `\(X_t\)` es distribuída normalmente, para `\(T\)` y `\(l\)` suficientemente grandes, el estadístico se aproxima a la distribución `\(\chi^2_{(mk^2)}\)`.

---
### Ruido blanco


```r
sig=diag(3)
z=mvrnorm(200,rep(0,3),sig)
mq(z,4)
```

```
## Ljung-Box Statistics:  
##        m       Q(m)     df    p-value
## [1,]  1.00      6.94    9.00     0.64
## [2,]  2.00     12.17   18.00     0.84
## [3,]  3.00     18.18   27.00     0.90
## [4,]  4.00     39.65   36.00     0.31
```

&lt;img src="clase05_files/figure-html/unnamed-chunk-15-1.png" width="40%" /&gt;

---
### VARMA(p,q)

- Conocido como VARMA o MARMA.
- ARMA(p,q) vectorial de `\(k\)` dimensiones se define como

`$$X_{t}=\phi_0+ \sum_{i=1}^p \phi_i X_{t-i}  - \sum_{j=1}^q \theta_j {w}_{t-j} +a_{t}$$`
con `\(\phi_p, \theta_q \neq 0\)` y `\(\Sigma_w\)` definida positiva.
- Los coeficientes `\(\phi_i :i=1,...,p\)`, `\(\theta_j:j=1,...,q\)` son matrices `\(k \times k\)`


---
### VARMA(p,q)

- Al igual que el caso univariado, si un VARMA es estacionario se puede expresar su versión centrada, o bien sin pérdida de generalidad suponer que `\(\phi_0=0\)`.

- Además, su representación es similar al caso univariado

`$$\phi(B) X_{t}= \theta(B) a_{t}$$`
en donde

`\(\phi(B)=I- \phi_1 B-...- \phi_p B^p\)` es el operador autorregresivo y

`\(\theta(B)=I-\theta_1 B-...- \theta_q B^q\)` es el operador de medias móviles.

---
### VARMA(p,q)

- El modelo VARMA se dice que es:
  - **Causal (estacionario)** si las raíces de `\(|\phi(B)|\)`, están fuera del círculo unitario.
  - **Invertible** si las raíces de `\(|\theta(B)|\)`, están fuera del círculo unitario.

- De la misma forma, si se satisfacen estas condiciones, el modelo tiene su representación `\(AR\)` y `\(MA\)` de orden infinito.

---
### En la próxima clase veremos

### VAR(p)

---

class: center, middle

## Thanks!

Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan).

The chakra comes from [remark.js](https://remarkjs.com), [**knitr**](http://yihui.org/knitr), and [R Markdown](https://rmarkdown.rstudio.com).

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create();
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
